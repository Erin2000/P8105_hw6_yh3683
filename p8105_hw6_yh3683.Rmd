---
title: "p8105_hw6_yh3683"
author: "Yining He"
date: "2024-11-21"
output: github_document
---
```{r include=FALSE}
library(tidyverse)
library(rnoaa)
library(dplyr)
library(broom)
library(purrr)
library(ggplot2)
library(modelr)
library(mgcv)
library(readxl)
library(rsample)
```


# Problem1
```{r echo=TRUE}
weather_df <- rnoaa::meteo_pull_monitors(
  c("USW00094728"),
  var = c("PRCP", "TMIN", "TMAX"),
  date_min = "2017-01-01",
  date_max = "2017-12-31"
) %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10
  ) %>%
  select(name, id, everything())

view(weather_df)
```

```{r echo=TRUE}
set.seed(123)

# Generate 5000 bootstrap samples and compute statistics
bootstrap_results = tibble(strap_number = 1:5000) %>%
  mutate(
  
    strap_sample = map(strap_number, ~sample_n(weather_df, size = nrow(weather_df), replace = TRUE)),
    
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    
    r_squared = map_dbl(models, ~glance(.x)$r.squared),
    
    # Extract coefficients and compute log(β0*β1)
    log_betas = map_dbl(models, ~{
      coefs = tidy(.x)$estimate
      log(coefs[1] * coefs[2])
    })
  )
```

```{r echo=TRUE}

# Distribution of R-squared
p1 = ggplot(bootstrap_results, aes(x = r_squared)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of R-squared",
    x = "R-squared",
    y = "Density"
  ) +
  theme_minimal()

# Distribution of log(β0*β1)
p2 = ggplot(bootstrap_results, aes(x = log_betas)) +
  geom_density(fill = "lightgreen", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of log(β0*β1)",
    x = "log(β0*β1)",
    y = "Density"
  ) +
  theme_minimal()

library(patchwork)
p1 + p2
```
```{r echo=FALSE}
# Calculate 95% confidence intervals
r_squared_ci = quantile(bootstrap_results$r_squared, c(0.025, 0.975))
log_betas_ci = quantile(bootstrap_results$log_betas, c(0.025, 0.975))
```
```{r echo=FALSE}
cat("\n95% Confidence Interval for R-squared:", 
    "\nLower bound:", round(r_squared_ci[1], 4),
    "\nUpper bound:", round(r_squared_ci[2], 4))
```

The bootstrap analysis with 5000 samples of the 2017 Central Park weather data shows R-squared values ranging from 0.89 to 0.93 (95% CI), with a symmetrical distribution centered around 0.91. This indicates that minimum temperature explains approximately 90% of the variation in maximum temperature.

```{r echo=FALSE}
cat("\n\n95% Confidence Interval for log(β0*β1):", 
    "\nLower bound:", round(log_betas_ci[1], 4),
    "\nUpper bound:", round(log_betas_ci[2], 4))
```
The log(β0*β1) estimates display a normal distribution centered around 2.0, with a 95% confidence interval of [1.96, 2.06]. This entirely positive and narrow interval confirms a significant and stable positive relationship between minimum and maximum temperatures.

# Problem 2

```{r echo=TRUE, warning=FALSE}
homicide_data <- read.csv("homicide-data.csv", stringsAsFactors = FALSE, encoding = "latin1")

homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

homicide_data <- homicide_data %>%
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
         victim_race %in% c("White", "Black"))

homicide_data <- homicide_data %>%
  mutate(victim_age = as.numeric(victim_age))

homicide_data <- homicide_data %>%
  mutate(solved = ifelse(disposition %in% c("Closed by arrest", "Closed without arrest"), 1, 0))

view(homicide_data)
```
```{r echo=TRUE, warning=FALSE}
baltimore_data <- homicide_data %>%
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model
baltimore_glm <- glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore_data, family = "binomial")

# Apply broom::tidy to the glm object
baltimore_glm_tidy <- broom::tidy(baltimore_glm, conf.int = TRUE, exponentiate = TRUE)

baltimore_or <- baltimore_glm_tidy %>%
  filter(term == "victim_sexMale") %>%
  select(estimate, conf.low, conf.high)

print(baltimore_or)
```

The odds ratio for solving homicides involving male victims in Baltimore is 0.3547, with a confidence interval of 0.2672 to 0.4679. This indicates significantly lower odds of solving male victim cases compared to female victims.

```{r echo=TRUE}
#Logistic Regression for Each City
fit_glm <- function(df) {
  glm(solved ~ victim_age + victim_sex + victim_race, data = df, family = "binomial") %>%
    broom::tidy(conf.int = TRUE, exponentiate = TRUE) %>%
    filter(term == "victim_sexMale") %>%
    select(estimate, conf.low, conf.high)
}

city_results <- homicide_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(model_results = map(data, fit_glm)) %>%
  unnest(model_results)

view(city_results)
```
```{r echo=TRUE}
city_results <- city_results %>%
  arrange(estimate)
ggplot(city_results, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Estimated Odds Ratios for Solving Homicides by City",
       x = "City",
       y = "Odds Ratio (Male vs Female)") +
  theme_minimal()
```

The plot shows the estimated odds ratios for solving homicides involving male victims compared to female victims across various U.S. cities. There is notable variation, with some cities (e.g., Fresno, CA, and Minneapolis, MN) showing higher odds of solving male homicides, while others (e.g., New York, NY) show higher odds for female homicides. 


# Probelm 3

Cleaned the data by checking for missing values and converting necessary variables into appropriate types
```{r}
birthweight <- read.csv("birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present"))
  )

# Check for missing values
sum(is.na(birthweight))
```

Defined the formula bwt ~ wtgain + gaweeks + smoken based on hypothesized relationships
```{r}
my_model <- lm(bwt ~ wtgain + gaweeks + smoken, data = birthweight)
summary(my_model)

birthweight <- birthweight %>%
  add_predictions(my_model) %>%
  add_residuals(my_model)

ggplot(birthweight, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values for My Model",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()

```

This plot indicates no clear patterns, suggesting that the linear regression model fits the data reasonably well. While there are some outliers, the residuals are generally centered and exhibit homoscedasticity (constant variance).


 Compare my model to two others:
```{r}
my_model <- lm(bwt ~ wtgain + gaweeks + smoken, data = birthweight)
second_model <- lm(bwt ~ blength + gaweeks, data = birthweight)
third_model <- lm(bwt ~ bhead * blength * babysex, data = birthweight)

residuals_my <- residuals(my_model)
residuals_second <- residuals(second_model)
residuals_third <- residuals(third_model)


residuals_data <- bind_rows(
  data.frame(Model = "My Model", Residuals = residuals_my),
  data.frame(Model = "Second Model", Residuals = residuals_second),
  data.frame(Model = "Third Model", Residuals = residuals_third)
)

ggplot(residuals_data, aes(x = Model, y = Residuals, fill = Model)) +
  geom_violin(alpha = 0.7) +
  labs(
    title = "Violin Plots of Residuals for Each Model",
    x = "Model",
    y = "Residuals"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel1")

```
The Plot shows residuals centered around 0 for all models, indicating unbiased predictions. The Third Model has wider tails, suggesting larger deviations, while My Model and the Second Model have tighter distributions, indicating better performance.


```{r}
# Cross-validation setup
set.seed(42)
cv_split <- crossv_mc(birthweight, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble)
  )

# Calculate RMSE for each model
cv_results <- cv_split %>%
  mutate(
    rmse_my = map2_dbl(train, test, ~ sqrt(mean((predict(my_model, newdata = .y) - .y$bwt)^2))),
    rmse_second = map2_dbl(train, test, ~ sqrt(mean((predict(second_model, newdata = .y) - .y$bwt)^2))),
    rmse_third = map2_dbl(train, test, ~ sqrt(mean((predict(third_model, newdata = .y) - .y$bwt)^2)))
  ) %>%
  pivot_longer(cols = starts_with("rmse"), names_to = "Model", values_to = "RMSE") %>%
  mutate(Model = str_replace(Model, "rmse_", ""))  # Clean up model names

# Plot RMSE violin plots
ggplot(cv_results, aes(x = Model, y = RMSE, fill = Model)) +
  geom_violin(alpha = 0.7) +
  labs(
    title = "Violin Plots of RMSE for Each Model",
    x = "Model",
    y = "RMSE"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel2")


```
The Second Model (using blength and gaweeks) makes it the most accurate predictor of birthweight. My Model performs moderately with a slightly higher RMSE, while the Third Model has poorer performance likely due to overfitting caused by the inclusion of complex interactions.













