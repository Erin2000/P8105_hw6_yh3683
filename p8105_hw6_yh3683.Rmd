---
title: "p8105_hw6_yh3683"
author: "Yining He"
date: "2024-11-21"
output: github_document
---
```{r include=FALSE}
library(tidyverse)
library(rnoaa)
library(dplyr)
library(broom)
library(purrr)
library(ggplot2)
library(modelr)
library(mgcv)
library(readxl)
```


# Problem1
```{r echo=FALSE}
weather_df <- rnoaa::meteo_pull_monitors(
  c("USW00094728"),
  var = c("PRCP", "TMIN", "TMAX"),
  date_min = "2017-01-01",
  date_max = "2017-12-31"
) %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10
  ) %>%
  select(name, id, everything())

view(weather_df)
```

```{r echo=FALSE}
set.seed(123)

# Generate 5000 bootstrap samples and compute statistics
bootstrap_results = tibble(strap_number = 1:5000) %>%
  mutate(
  
    strap_sample = map(strap_number, ~sample_n(weather_df, size = nrow(weather_df), replace = TRUE)),
    
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    
    r_squared = map_dbl(models, ~glance(.x)$r.squared),
    
    # Extract coefficients and compute log(β0*β1)
    log_betas = map_dbl(models, ~{
      coefs = tidy(.x)$estimate
      log(coefs[1] * coefs[2])
    })
  )
```

```{r echo=FALSE}

# Distribution of R-squared
p1 = ggplot(bootstrap_results, aes(x = r_squared)) +
  geom_density(fill = "lightblue", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of R-squared",
    x = "R-squared",
    y = "Density"
  ) +
  theme_minimal()

# Distribution of log(β0*β1)
p2 = ggplot(bootstrap_results, aes(x = log_betas)) +
  geom_density(fill = "lightgreen", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of log(β0*β1)",
    x = "log(β0*β1)",
    y = "Density"
  ) +
  theme_minimal()

library(patchwork)
p1 + p2
```
```{r echo=FALSE}
# Calculate 95% confidence intervals
r_squared_ci = quantile(bootstrap_results$r_squared, c(0.025, 0.975))
log_betas_ci = quantile(bootstrap_results$log_betas, c(0.025, 0.975))
```
```{r echo=FALSE}
cat("\n95% Confidence Interval for R-squared:", 
    "\nLower bound:", round(r_squared_ci[1], 4),
    "\nUpper bound:", round(r_squared_ci[2], 4))
```

The bootstrap analysis with 5000 samples of the 2017 Central Park weather data shows R-squared values ranging from 0.89 to 0.93 (95% CI), with a symmetrical distribution centered around 0.91. This indicates that minimum temperature explains approximately 90% of the variation in maximum temperature.

```{r echo=FALSE}
cat("\n\n95% Confidence Interval for log(β0*β1):", 
    "\nLower bound:", round(log_betas_ci[1], 4),
    "\nUpper bound:", round(log_betas_ci[2], 4))
```
The log(β0*β1) estimates display a normal distribution centered around 2.0, with a 95% confidence interval of [1.96, 2.06]. This entirely positive and narrow interval confirms a significant and stable positive relationship between minimum and maximum temperatures.

# Problem 2

```{r echo=FALSE}
homicide_data <- read.csv("homicide-data.csv", stringsAsFactors = FALSE, encoding = "latin1")

homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

homicide_data <- homicide_data %>%
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
         victim_race %in% c("White", "Black"))

homicide_data <- homicide_data %>%
  mutate(victim_age = as.numeric(victim_age))

homicide_data <- homicide_data %>%
  mutate(solved = ifelse(disposition %in% c("Closed by arrest", "Closed without arrest"), 1, 0))

view(homicide_data)
```
```{r echo=FALSE}
baltimore_data <- homicide_data %>%
  filter(city_state == "Baltimore, MD")

# Fit logistic regression model
baltimore_glm <- glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore_data, family = "binomial")

# Apply broom::tidy to the glm object
baltimore_glm_tidy <- broom::tidy(baltimore_glm, conf.int = TRUE, exponentiate = TRUE)

baltimore_or <- baltimore_glm_tidy %>%
  filter(term == "victim_sexMale") %>%
  select(estimate, conf.low, conf.high)

print(baltimore_or)
```

The odds ratio for solving homicides involving male victims in Baltimore is 0.3547, with a confidence interval of 0.2672 to 0.4679. This indicates significantly lower odds of solving male victim cases compared to female victims.

```{r echo=FALSE}
#Logistic Regression for Each City
fit_glm <- function(df) {
  glm(solved ~ victim_age + victim_sex + victim_race, data = df, family = "binomial") %>%
    broom::tidy(conf.int = TRUE, exponentiate = TRUE) %>%
    filter(term == "victim_sexMale") %>%
    select(estimate, conf.low, conf.high)
}

city_results <- homicide_data %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(model_results = map(data, fit_glm)) %>%
  unnest(model_results)

view(city_results)
```
```{r echo=FALSE}
city_results <- city_results %>%
  arrange(estimate)
ggplot(city_results, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Estimated Odds Ratios for Solving Homicides by City",
       x = "City",
       y = "Odds Ratio (Male vs Female)") +
  theme_minimal()
```

The plot shows the estimated odds ratios for solving homicides involving male victims compared to female victims across various U.S. cities. There is notable variation, with some cities (e.g., Fresno, CA, and Minneapolis, MN) showing higher odds of solving male homicides, while others (e.g., New York, NY) show higher odds for female homicides. 


#Probelm 3
```{r}
birthweight_data <- read_csv("birthweight.csv") %>%
  mutate(
    # Convert numeric to factor where appropriate
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                  labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                  labels = c("White", "Black", "Asian", "Puerto Rican", "Other"))
  )

# Check for missing data
missing_summary <- sapply(birthweight_data, function(x) sum(is.na(x)))
print("Missing values by column:")
print(missing_summary)


my_model <- lm(bwt ~ bhead + blength + gaweeks + smoken + ppbmi + wtgain + 
               momage + babysex + mrace, data = birthweight_data)

# Create residuals vs fitted plot
birthweight_data %>%
  add_predictions(my_model) %>%
  add_residuals(my_model) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals",
       title = "Residuals vs Fitted Values Plot") +
  theme_minimal()
```
The residuals plot shows a slight trend and some clustering, suggesting possible model misspecification or unaddressed non-linear relationships. A few outliers are also present, which might influence the model's parameters. Despite these issues, the deviation in the plotted variables is minimal, and most points lie within an acceptable range, indicating that the model's predictions are reasonably unbiased.







```{r echo=FALSE}
model_1 <- lm(bwt ~ blength + gaweeks, data = birthweight_data)

model_2 <- lm(bwt ~ bhead * blength * babysex, data = birthweight_data)

# Cross-validation function
cv_rmse <- function(model, data) {
  predictions <- predict(model, data)
  sqrt(mean((data$bwt - predictions)^2, na.rm = TRUE))
}

# Perform cross-validation
set.seed(123)
cv_df <- crossv_mc(birthweight_data, n = 100) 

# Calculate RMSE for each model in each fold
cv_results <- cv_df %>%
  mutate(
    my_model = map(train, ~lm(bwt ~ bhead + blength + gaweeks + smoken + ppbmi + 
                             wtgain + momage + babysex + mrace, data = .x)),
    model_1  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2  = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
    
    rmse_my_model = map2_dbl(my_model, test, ~cv_rmse(model = .x, data = as.data.frame(.y))),
    rmse_model_1  = map2_dbl(model_1, test, ~cv_rmse(model = .x, data = as.data.frame(.y))),
    rmse_model_2  = map2_dbl(model_2, test, ~cv_rmse(model = .x, data = as.data.frame(.y)))
  )

# Summarize cross-validation results
cv_summary <- cv_results %>%
  summarize(
    mean_rmse_my_model = mean(rmse_my_model),
    mean_rmse_model_1 = mean(rmse_model_1),
    mean_rmse_model_2 = mean(rmse_model_2),
    sd_rmse_my_model = sd(rmse_my_model),
    sd_rmse_model_1 = sd(rmse_model_1),
    sd_rmse_model_2 = sd(rmse_model_2)
  )

# Create visualization of cross-validation results
cv_results %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_violin(aes(fill = model), alpha = 0.5) +
  geom_boxplot(width = 0.1) +
  labs(x = "Model", y = "RMSE",
       title = "Cross-validated Prediction Error Comparison") +
  theme_minimal() +
  theme(legend.position = "none")

# Print summary of cross-validation results
print(cv_summary)
```















